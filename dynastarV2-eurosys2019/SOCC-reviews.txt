
PRESENTATION
-why are so many separate invocations of a-multicast required here?
-How do you choose the host partition where the command is executed?
-How often does the oracle re-partition the data? What factors determine it?
-What objective function are you optimizing for when the METIS graph partitioning algorithm is run?
-The design is very high-level and does not detail how the partitioning works.
-The base communication means is an atomic multicast, which can be a source of overhead, but it is not clear whether this is implemented. 
-The oracle keeps track of the dependencies, but how are the dependencies used to plan a new partition? 
-How exactly does the new partitioning scheme balance between placing dependent objects in the same partition and balancing the load over all partitions? 
-How frequently should partitioning happen and who should trigger the partition on which occasions? 
-Invalidation of the workload graph on the client side is mentioned but no protocol is described for invalidations. 
-Also, how are client failures handled. For e.g., if an invalidation is not received by a failed client.
-The implementation section, however, doesn't talk about how atomic multicast has been implemented. 
[DONE]-Section 4 is more appropriate as a appendix section 
[DONE]-I'm not sure what the footnote on page 2 really means ("We assume the existence of an atomic multicast oracle"). 
[DONE]-Why even define r-multicast if it is used only for interactions between just two processes (Fig 1)?

PERFORMANCE
-sluggish 10KB TPC transactions per second, and absolutely no sign of improved speed as the number of partitions (nodes) increases
	> let's try a EC2 deployment of TPCC with up to 128 partitions
-the experiments don't trigger frequent migration, 
	> in social network with 8P, make a user become celebrity, then reconfigure
-and no effort was made to actually measure the overheads due to migration as a function of data size
	> in above experiment, measure moved data during execution; also measure number of queries answered
-measurement of the data migration overhead as a function of cluster size (number of partitions), data size, and frequency of migration
	> in scalability results, compute average amount of data moved over partition, number of queries at oracle
-What happens if the next command also accesses the same or subset of variables? 
	> skip
-What is the cost of temporarily moving the variables for each command? 
	> measure amount of moved across partitions during experiments
-figure 3 why is the latency as well as throughput high of DynaStar compared to S-SMR (e.g., 8 and 16 partitions)?
	> skip
-depending on the workload and the frequency of repartitioning, won't sending data back and forth become an overhead? 
	> already taken care of
-Showing a breakdown of data being moved would clear this question. 
	> we'll how data moves around from source to destination partitions
-It would have been nice to target real world applications that require it. It's not clear to me that Twitter-like application has that need.
	> we'll use TPCC and Higgs workload; explain that with DynaStar we don't causality violations
-Does the oracle really scale? Sometimes, the size of the workload-graph could be bigger than the store itself. How would this approach scale?
	> we'll measure activity at the oracle
-The size of the workload used for evaluation is not clearly spelled out. What is the number of state variables in the TPCC benchmark?
	> fix this in the text
-The experimental setup is a single cluster, other scenarios where state-machine-replication is used tend to be geo-replicated (Spanner). 
	> skip
-Evaluation needs to demonstrate failure scenarios and cost of repartitioning.
	> failures???

NOVELTY & RELATED WORK
-The concept is not really "new": data migration as opposed to remote access was explored in many distributed transactional systems in the 1980's
-Cosmos or other commercial systems
-There is a great body of work surrounding distributed transactions

DESIGN ISSUES
-It's even more restrictive to expect that clients can cache the entire workload-graph in memory. 

TYPOS AND MINOR STUFF
I got a little confused following some of the Algorithms, perhaps related to some typos etc? Specifically in Algorithm 2:
- line 8: target() is not clear, and G_{W} is undefined
- line 11: given that P is in P_{s}, can't you simplify as "P = P_{d}" versus not?
- line 20: is P_{v} here supposed to be P? This is the logic for a server in partition P, right?
- line 25: what is 'newpartitioning'? not referred to later
- line 26: what is 'plan'? (I assume this is supposed to related to line 25)

And in Algorithm 3:
- line 30: what is G_{W}? He seems important (see above)
- line 36: newpartioning and plan once more; please fix [as per Alg 2]



Review #216A
===========================================================================
3. Weak accept
4. Expert

The concept is not really "new": data migration as opposed to remote access was explored in many distributed transactional systems in the 1980's, and the whole point of Lamport's Paxos work was to show how SMR can be supported and formalized.  On the other hand, I am not aware of any contemporary system that implements this functionality in this way, hence the work is of definite interest.

Least impressive was the actual performance obtained: a sluggish 10KB TPC transactions per second, and absolutely no sign of improved speed as the number of partitions (nodes) increases.  So no hope for hitting big numbers even with more nodes.   

Although dynamic data partitioning and migration is central to the discussion, the experiments don't trigger frequent migration, and no effort was made to actually measure the overheads due to migration as a function of data size.  I would presume that those run some risk of growing into a serious concern at large scale and actually slow things down.  There is also no real evaluation of the optimal frequency at which to do repartitioning.  

If feasible, it would be nice to see a measurement of the data migration overhead as a function of cluster size (number of partitions), data size, and frequency of migration.  

Can you show any evidence from the literature that Cosmos or other commercial systems suffers from not having this?  I think you will discover that Cosmos can regenerate any lost data using "compute functions" it applies to the raw inputs in some sequence.  Thus in Cosmos, a replica is just a cached version and the underlying data is fundamentally immutable.   

In figure 1, r-multicast is used only for what look like point to point message sends.  I don’t see any other use of the protocol at all.  Why even define this primitive if it is used only for interactions between just two processes?  Conversely, why are so many separate invocations of a-multicast required here?  Shouldn't it be possible to do the entire SMR operation with just one a-multicast per partition accessed?

I’m speculating here, because you didn’t tell us how atomic multicast was implemented.  But your group maintains LibPaxos, and use of Paxos for updates strikes me as overkill.


Review #216B
===========================================================================
2. Weak reject
3. Knowledgeable

1) While a command is executed variables are temporarily located to host partitions, and then moved back to the source partitions. What happens if the next command also accesses the same or subset of variables? What is the cost of temporarily moving the variables for each command? How do you choose the host partition where the command is executed?
2) How often does the oracle re-partition the data? What factors determine it?
3) What objective function are you optimizing for when the METIS graph partitioning algorithm is run?
4) In figure 3 why is the latency as well as throughput high of DynaStar compared to S-SMR (e.g., 8 and 16 partitions)? I would have expected one of these metrics to be lower for the other to be higher.
5) Minor: Section 4 is more appropriate as a appendix section since the general idea is intuitive. It may give you more space to add implementation details.

Review #216C
===========================================================================
3. Weak accept
2. Some familiarity

I got a little confused following some of the Algorithms, perhaps related to some typos etc? Specifically in Algorithm 2:
- line 8: target() is not clear, and G_{W} is undefined
- line 11: given that P is in P_{s}, can't you simplify as "P = P_{d}" versus not?
- line 20: is P_{v} here supposed to be P? This is the logic for a server in partition P, right?
- line 25: what is 'newpartitioning'? not referred to later
- line 26: what is 'plan'? (I assume this is supposed to related to line 25)

And in Algorithm 3:
- line 30: what is G_{W}? He seems important (see above)
- line 36: newpartioning and plan once more; please fix [as per Alg 2]

Review #216D
===========================================================================
2. Weak reject
3. Knowledgeable

1) The design is very high-level and does not detail how the partitioning works.
2) The base communication means is an atomic multicast, which can be a source of overhead, but it is not clear whether this is implemented. 

The biggest complaint that I have with this paper is that the paper presents a high-level design but does not cover the small details. The oracle keeps track of the dependencies, but how are the dependencies used to plan a new partition? How exactly does the new partitioning scheme balance between placing dependent objects in the same partition and balancing the load over all partitions? How frequently should partitioning happen and who should trigger the partition on which occasions? Most of these questions are not answered or answered vaguely which leaves a hole for the practical use of the system. 

The performance evaluation seems to indicate that repartitioning doesn't significantly impact the performance, but depending on the workload and the frequency of repartitioning, won't sending data back and forth become an overhead? Showing a breakdown of data being moved would clear this question. 

Is the atomic multicast implemented in your system as it can be another source of overhead? The footnote indicates that there is an assumption about it but it is not clear whether it is just for the explanation of communication primitives or if it is omitted in the system as well. 

The paper started with a state machine replication and considered partitions and cross-partition transactions. Thinking about it inversely, this system seems to have a lot to do with a distributed transaction system which typically starts from a distributed transaction but later added replication (using state machine replication) for reliability. There is a great body of work surrounding distributed transactions and how would you compare your work with it? If an object in a partition has a dependency to multiple other partitions, then moving the object back and forth across the destination partition may be less efficient than just executing a typical distributed transaction protocol. Of course the repartitioning will solve this problem but comparison with distributed transaction would give better intuition about your system.

Review #216E
===========================================================================
2. Weak reject
3. Knowledgeable

1. One of the main benefits of the proposed approach is getting linearizability. It would have been nice to target real world applications that require it. It's not clear to me that Twitter-like application has that need.

2. Does the oracle really scale? State is required to track locations of each state variables, which has to fit in a single partition and even in memory for the present implementation. Now imagine an application consisting of a large-scale Key-Value store or Database with billions of keys, each key represents a state variable. It's not going to be the case that the entire per-key state will fit into a single partition to begin with. Sometimes, the size of the workload-graph could be bigger than the store itself. How would this approach scale?

3. It's even more restrictive to expect that clients can cache the entire workload-graph in memory. This doesn't scale for large state space at all.  Partitions in SMR are primarily required when there is a large state space, so the proposed solutions should be targeted at such scales. The current architecture doesn't seem to be.

4. Invalidation of the workload graph on the client side is mentioned but no protocol is described for invalidations. Also, how are client failures handled. For e.g., if an invalidation is not received by a failed client.

5. The choice of state variable placement doesn't seem to take into account the cost of migrating the state and any resulting drop in throughout during state migration.

6. The operations are executed in a linear chain for requests with state stored on multiple partitions. This could not have very high xPut for multi-partition operations. Otoh, transaction protocols on distributed state are able to overcome performance issue via various techniques for e.g., optimistic concurrency control. They don't provide linearizability however. In that context, there should be a justification of how limited xPut would be useful enough for real world applications.

Implementation / Evaluation

7. The approach entirely depends on the performance and scalability of atomic multicast. The implementation section, however, doesn't talk about how atomic multicast has been implemented. I'm not sure what the footnote on page 2 really means ("We assume the existence of an atomic multicast oracle"). If an oracle was used in the evaluation then the evaluation doesn't demonstrate a real world setting.

8. The size of the workload used for evaluation is not clearly spelled out. What is the number of state variables in the TPCC benchmark? For the twitter-like benchmark, the size of the workload graph in Fig. 7 is 1GB. Extrapolating from this number, the state store is pretty small for the twitter-like example. It could perhaps fit in the memory of a single machine. This example and workload is not representative of a high-scale scenario and doesn't demonstrate performance and scalability adequately in my opinion.

9. Fig. 3 shows scalability up to 16 partitions with increasing latency. I'm curious to know what the saturation limit for this protocol is, how many partitions before the incremental benefit of increased xPut diminishes. That would explain real scalability of this approach.

10. The experimental setup is a single cluster, other scenarios where state-machine-replication is used tend to be geo-replicated (Spanner). For a single cluster setting, I believe better network interlinks and high-performance machines make it possible to get much higher throughput than the presented evaluation (15k-20k updates per second).

11. Evaluation needs to demonstrate failure scenarios and cost of repartitioning.