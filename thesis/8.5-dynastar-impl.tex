%!TEX root =  main.tex
\section{Implementation}
\label{sec:dynastar-implementation}

\subsection{Atomic multicast}

Our \dynastar prototype uses the BaseCast atomic multicast protocol
\cite{coelho2017fast}, available as open
source.\footnote{https://bitbucket.org/paulo\_coelho/libmcast} Each group of
servers in BaseCast executes an instance of
Multi-Paxos.\footnote{http://libpaxos.sourceforge.net/paxos\_projects.php\#libpaxos3}
Groups coordinate to ensure that commands multicast to multiple groups are
consistently ordered (as defined by the atomic multicast properties
\S\ref{sec:amcast}).
%Commands multicast to multiple groups coordinate to ensure that commands are
%consistently ordered (as defined by the atomic multicast properties
%\S\ref{sec:amcast}).
BaseCast is a genuine atomic multicast in that only the sender and destination
replicas of a multicast message communicate to order the multicast message.
% A genuine atomic multicast is the foundation of scalable systems, since it does
% not rely on a fixed group of processes and does not involve all processes.

\subsection {Graph partitioning with METIS}
% \fxnote{adding more details of Metis}
\lle{The default implementation of \dynastar uses
METIS\footnote{http://glaros.dtc.umn.edu/gkhome/views/metis} to provide a
partitioning based on the workload graph. METIS is a graph partitioning method
based on multilevel $l$-way partitioning algorithms
\cite{karypis1998multilevelk}, which is able to compute a balanced bipartition.
The overall sequence of METIS consists of three phases: coarsening, initial
partitioning, and refining. In the first phase, coarsening, METIS takes a large
graph and creates successively smaller graphs that are good representations of
the original graph. METIS then partitions the smaller graph in the second
phase. In the third phase, METIS projects and refines the partition of the
smaller graph onto the original graph. While partitioning a graph, METIS aims to
reduce the number of multi-partition commands (edge-cuts) while trying to keep
the various partitions balanced. Recently, METIS has been improved in
performance especially for power-law graphs \cite{abou2006multilevel}.}

\lle{We configured METIS to allow a 20\% unbalance among partitions. METIS
repartitions a graph without considering previous partitions. Consequently,
\dynastar may need to relocate a large number of objects upon a repartitioning.
Other partitioning techniques could be used to introduce incremental graph
partitioning \cite{SerafiniTEPAS16}.}

\subsection{\dynastar}

Our  \dynastar prototype is written as a Java 8 library. Application designers
who use \dynastar to implement a replicated service must extend three key
classes:
 \begin{itemize}

 \item[--] \emph{PRObject}: provides a common interface for replicated data
 items. All instance of \emph{PRObject}'s sub-classes are replicated by the
 framework(i.e., objects are distributed among partitions). The application is
 agnostic to the location of those objects. \dynastar intercepts all calls to
 replicated objects and forward them to associated partition automatically.

 \item[--] \emph{ProxyClient}: provides the communication between application
 client and server, while encapsulating all complex logic of handling caches or
 retried requests. The proxy client also allows sending multiple asynchronous
 requests, and delivering corresponding response to each request.

 \item[--] \emph{PartitionStateMachine}: encapsulates the logic of the server
  proxy. The server logic is written without knowledge of the actual
  partitioning scheme. In other words, developer programs for classical state
  machine replication (i.e., full replication). The \dynastar library handles
  all communication between partitions and the oracle transparently. Objects
  that are involved in application's command will be available to the
  partition at the time it is accessed by the partitions.

 \item[--] \emph{OracleStateMachine}: computes the mapping of objects to
  partitions. The oracle can be configured to trigger repartitioning in
  different ways: repartitioning request from application, based on the number
  of changes to the graph, or based on some interval of time. 
 \end{itemize}

We note one important implementation detail.  The oracle is multi-threaded: it
can serve requests while computing a new partitioning concurrently. To ensure
that all replicas start using the new partitioning consistently, the oracle
identifies each partitioning with a unique id.  When an oracle replica finishes
a repartitioning, it atomically multicasts the id of the new partitioning to
all replicas of the oracle.  The first delivered id message defines the order
of the new partitioning with respect to other oracle operations.


\subsection{TPC-C benchmark}
\label{sec:imp:tpcc}

%On average, 10\% of transactions are distributed transactions.

TPC-C is an industry standard for evaluating the performance of OLTP systems
\cite{tpcc}. TPC-C implements a wholesale supplier company. The company has a
number of distributed sales districts and associated warehouses. Each warehouse
has 10 districts. Each district services 3,000 customers. Each warehouse
maintains a stock of 100,000 items. The TPC-C database consists of 9 tables and
five transaction types that simulate a warehouse-centric order processing
application: \emph{New-Order} (45\% of transactions in the workload),
\emph{Payment} (43\%), \emph{Delivery} (4\%), \emph{Order-Status} (4\%) and
\emph{Stock-Level} (4\%).

We implemented a Java version of TPC-C that runs on top of \dynastar. Each row
in TPC-C tables is an object in \dynastar. The oracle models the workload at the
granularity of districts, thus each district and warehouse is a node in the
graph. If a transaction accesses a district and a warehouse, the oracle will
create an edge between that district and the warehouse. The objects (e.g.,
customers, orders) that belong to a district are considered part of district.
However, if a transaction requires objects from multiple districts, only those
objects will be moved on demand, rather than the whole district. The ITEM table
is replicated in all servers, since it is not updated in the benchmark. A
transaction is a set of commands that access those objects, implemented as
server procedures.

\subsection{Social network application}
\label{sec:imp:\dynastarappname}

Using \dynastar{}, we have also developed a Twitter-like social network service,
named Chirper. In our social network, users can follow, unfollow, post, or read
other users' tweets according to whom the user is following. Like Twitter, users
are constrained to posting 140-character messages.

Each user in the social network corresponds to a node in a graph. If one user
follows another, a directed edge is created from the follower to the followee.
Each user has an associated \emph{timeline}, which is a sequence of post
messages from the people that the user follows. Thus, when a user issues a post
command, it results in writing the message to the timeline of all the user's
followers.  In contrast, when users read their own timeline, they only need to
access the state associated with their own node.

Since \dynastar guarantees linearizable executions, any causal dependencies
between posts in \dynastarappname\ will be seen in the correct order. More
precisely, if user B posts a message after receiving a message posted by user A,
no user who follows A and B will see B's message before seeing A's message.

Overall, in \dynastarappname, post, follow or unfollow commands can lead to
object moves.  Follow and unfollow commands can involve at most two partitions,
while posts may require object moves from many partitions.

%Of course, other implementations are possible. But, given that users in social
%networks spend most of the time reading (i.e., performing
%getTimeline)~\cite{facebookTAO}, it is useful to implement getTimeline as an
%efficient single-partition command.


\subsection{Alternative system}

We compare \dynastar{} to an optimized version of S-SMR~\cite{bezerra2014ssmr}
and DS-SMR. S-SMR scales performance with the number of partitions under a
variety of workloads. It differs from \dynastar{} in two important aspects:
multi-partition commands are executed by all involved partitions, after the
partitions exchange needed state for the execution of the command, and S-SMR
supports static state partitioning. In our experiments, we manually optimize
S-SMR's partitioning with knowledge about the workload. In the experiments, we
refer to this system and configuration as S-SMR*.
%Since all three systems (S-SMR, DS-SMR, and \dynastar) provide a common
%application-level interface, there was no additional work required to port the
%social network application.

