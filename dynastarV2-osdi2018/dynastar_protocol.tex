%!TEX root =  main.tex
\section{\dynastar}
%\section{Optimized dynamic state partitioning with \dynastar}
\label{sec:dynastar}

%In this section, we overview \dynastar's key ideas, present the protocol in detail, discuss some performance optimizations, and argue about \dynastar's correctness.
The key insights of \dynastar are to optimize state partitioning based on the workload and to relocate application state on-the-fly, without service disruption.
\begin{itemize}
\item \emph{Optimized state partitioning.}
\dynastar models a service workload as a graph $G = (V, E)$, where vertices represent state variables and edges dependencies between variables.
An edge connects two variables in the graph if a command accesses both of them.
A location oracle builds the workload graph based on feedback from the clients or partitions, as commands are executed, periodically computes a partitioning of the workload graph, and sends the partitioning to the various partitions.

\item \emph{On-the-fly relocation of service state.}
Based on this partitioning and the current location of variables, the partitions determine the destination for commands that access variables spread over multiple partitions.
Variables are moved on demand to the destination partition where the command will be executed. After the execution, variables are moved back to the source partition to keep the optimized partitioning.
\end{itemize}

%In \dynastar a move request is multicast together with the command that triggered the request.
%%a partition executes a command right after it has gathered all variables it needs.
%Therefore, differently from DS-SMR, \dynastar ensures termination without resorting to expensive mechanisms (i.e., S-SMR).

\subsection{Overview}
%\subsection{State partitioning as a graph problem}



\dynastar defines a dynamic mapping of variables to partitions.
Each variable $v$ is mapped to a partition $\ppm$, that is, $v \in \ppm$.
Such a mapping is managed by a partitioning oracle, implemented as a replicated service run by a group of server processes.
The oracle allows the mapping of variables to partitions to be retrieved or changed during execution.
In more detail, \dynastar\ distinguishes five types of commands:
$access(\omega)$ is an application command that accesses (reads or writes) variables in set $\omega \subseteq \vvm$,
$create(v)$ creates a new variable $v$ and initially maps it to a partition defined by the oracle,
$delete(v)$ removes $v$ from the service state,
% resulting in $part(v) = \emptyset$,
$move(v,\ppm_s,\ppm_d)$ moves variable $v$ from partition $\ppm_s$ to partition $\ppm_d$,
and $consult(C)$ asks the oracle which variables are accessed by command $C$, and which partition contains each of them.
The reply from the oracle is called a $prophecy$, and usually consists of a set of tuples $\langle v, \ppm \rangle$, meaning $v \in \ppm$.
% The other possible values for a prophecy are $ok$ and $nok$, which mean that command can and cannot be executed, respectively (more details in Section~\ref{sec:algorithm}).
%If $v$ is not part of the service state (i.e., it was deleted or never created), the prophecy will contain~$\langle v, \emptyset \rangle$.

% explain which partitions deliver each partitioning command:
% how are access, consult, create, move and delete implemented?

%Once the oracle is in place, 
Clients consult the oracle to know which partitions each command should be multicast to, based on the objects accessed by the command.
If the reply received from the oracle tells the client that the command accesses a single partition, the client multicasts the command to that partition.
If the command accesses objects from multiple partitions, the client first multicasts one or more $move$ commands to the oracle and to the involved partitions, with the intent of having all variables in the same partition.
Then, the command itself is multicast to the one partition that now holds all variables accessed by the command.
If a subsequent command accesses the same variables, it will also access a single partition.
Thus, the access patterns of commands will shape the mapping of variables to partitions, reducing the number of multi-partition commands.

Consulting the oracle and issuing the application command are done with separate calls to atomic multicast in \dynastar.
It may happen that, between those operations, the partitioning changes.
%We illustrate this in Figure~\ref{fig:move_case_1}.
%Commands $C_1$ and $C_2$ read variable $x$.
%Since partitioning is dynamic, the client issuing the commands first consults the oracle before multicasting each command.
%$C_1$ executes without the interference of other commands, so consulting the oracle and multicasting the command only once is enough for $C_1$ to be executed.
%However, before $C_2$ is multicast to $\ppm_1$, another client issues a $move$ command that relocates $x$ to $\ppm_2$.
%When $C_2$ is delivered at the servers of $\ppm_1$, the command is not executed, since $x$ is not available at $\ppm_1$ anymore.
%A similar situation may arise when a command accesses variables from multiple partitions, as it consists of multicasting at least three commands separately: $consult$, $move$ and $access$.
%The partitioning can change between the execution of any two of those commands.
%\begin{figure}[b!]
%  \includegraphics[width=\linewidth]{figures/move_case_1}
%  \caption{Consulting the oracle and issuing an application command consist of multiple calls to \amcast{}.}
%  \label{fig:move_case_1}
%\end{figure}
% \pagebreak
To solve this problem, the client multicasts the set of variables accessed along with each access command.
Upon delivery, each server checks the set of variables sent by the client.
If all variables in the set belong to the local partition, the command is executed; otherwise, a $retry$ message is sent back to the client.
When the client receives a $retry$ message, it consults the oracle again, possibly moves variables across partitions, and then reissues the access command.
To guarantee termination, if the command fails a certain number of times, the client multicasts the command to all partitions and the servers execute it as in the original \ssmr{}.



\subsection{The detailed protocol}

Algorithms~\ref{alg:client_proxy}, \ref{alg:server_proxy}, and \ref{alg:oracle_proxy} describe the client, server and oracle processes, respectively. 
For brevity, we omit the delete command since the coordination involved in the create and delete commands are analogous. 
In the discussion in this section, every command involves the oracle.
The oracle is replicated and handled as a partition.
In the next section, we explain how clients can use a cache to avoid the oracle in the execution of most commands.


\subsubsection{The client process} 

To execute a command, the client atomically multicasts the command to the oracle (Algorithm 1).
The oracle replies with a prophecy, which may already tell the client that the command cannot be executed (e.g., it needs a variable that does not exist, it tries to create a variable that already exists).
If the command can be executed, the client receives a prophecy containing the partition where the command will be executed. The client then waits for the result of the execution of the command.


% The client must retry the command if the partition cannot execute the command.
% This happens if the cache on client is invalid, some of the variables needed by the command were moved to another partition due a new partitioning. 
%To ensure that a command is eventually executed, after retrying a few times, the client falls back to using \ssmr{}, multicasting the command to all partitions (and the oracle, in case of a create or delete command).

\subsubsection{The server process} 

All servers keep a workload graph in their memory. When a server delivers a command $C$, multicast by the oracle, it first checks if it has all variables needed by the command. If the server has all such variables, it executes the command and sends the response back to the client (Tasks 1a and 3 in Algorithm~\ref{alg:server_proxy}).
If not all the variables needed by the command are in that partition, the server issues a move command that involves all partitions containing the needed variables (Task 1b and 2).
%If one or more variables are not stored in a single partition, the server returns a message to the client to retry the operation.
%This happens if the oracle moved some variables to another partition as part of another command. 
In this case, a server in the source partitions reliably multicasts all the needed variables stored locally to the destination partition and waits to receive them back.
Destination partition waits for a message from each source partition. Once all variables needed are available, destination partition executes the command $C$, sends the response back to the client, and returns the variables to their source.
Periodically, the servers deliver a new partitioning plan from the oracle (Task 4). Each server will send the variables to the designated partition as in the plan and wait for variables from other partitions. Once a server receives all variables, it updates its location map accordingly.
%When a server delivers a message to create a variable (and similarly to delete an existing variable), it coordinates with the oracle (Task 3).
%The exchange of signals between the partition where the variable will be created and the oracle ensures that interleaved executions between create and delete commands will not lead to violations of linearizability (i.e., this is essentially the execution of a multi-partition command involving the oracle and a partition~\cite{bezerra2014ssmr}).
To determine the destination partition for a command, the servers uses the last computed partitioning.

\subsubsection{The oracle} 

When the oracle delivers a request, it distinguishes between two cases (Task 1 in Algorithm~\ref{alg:oracle_proxy}).
\begin{itemize}
\item If the command is to create a variable $v$, and $v$ does not already exist, the oracle chooses a random partition for $v$, multicasts the create command to the partition and itself, and returns the partition to the client as a prophecy (Figure~\ref{fig:oracle_repartition}).
\item If the command reads and writes existing variables, the oracle first checks that all such variables exist.
If the variables exist and they are all in a single partition, the oracle multicasts the command to that partition for execution.
If the variables are distributed in multiple partitions, the oracle determines the destination partition, and atomically multicasts a command to the involved partitions and to itself so that all variables are gathered at the destination partition.
The destination partition executes the command once it has received all variables needed by the command, then returns those variables to their source partition.

%In either case, oracle returns a prophecy back to the client with the destination partition.
\end{itemize}

\input{algorithm_client_proxy}
\input{algorithm_server_proxy}
\input{algorithm_oracle_proxy}

\begin{figure*}
\begin{minipage}[b]{1\linewidth} % A minipage that covers the whole width of the page
\centering
      \includegraphics[width=0.9\linewidth]{figures/dynastar}
\end{minipage}
\caption{The execution of a create command and a write command in \dynastar.}
\label{fig:oracle_repartition}
\end{figure*}

Upon delivering a create (Task 2), the oracle updates its partition information.
As part of a create command, the oracle coordinates with the partition to ensure correctness (Task 3)~\cite{bezerra2014ssmr}.
%
The oracle also keeps track of the workload graph by receiving hints with variables (i.e., vertices in the graph) and executing commands (i.e., edges in the graph). These hints can be submitted by the clients or by the partitions, which collect data upon executing commands and periodically inform the oracle (Task 4).
The oracle computes a partitioning plan of the graph and multicasts it to all servers and to itself. Upon delivering new partition plan, the oracle updates its location map accordingly (Task 5).
% The oracle also keeps track of the workload graph, computes a partitioning of the graph, and determines the destination partition for move operations.
% To maintain the workload graph (Task 5), the oracle receives hints with variables (i.e., vertices in the graph) and executed commands (i.e., edges in the graph).

To compute an optimized partitioning, the oracle uses a graph partitioner.
A new partitioning can be requested by the application, by a partition, or by the oracle itself (e.g., upon delivering a certain number of hints).
To determine the destination partition of a set of variables, as part of a move, the oracle uses 
% the current location of variables and 
the last computed partitioning.

\subsection{Performance optimizations}
%\subsection{Performance optimizations}
\label{sec:optm}

We now describe two performance optimizations.

\textbf{Caching.} In the algorithm presented in the previous section, clients always need to involve the oracle, and the oracle dispatches every command to the partitions for execution.
Obviously, if every command involves the oracle, the system is unlikely to scale, as the oracle will likely become a bottleneck.
To address this issue, clients are equipped with a location cache.
Before submitting a command to the oracle, the client checks its location cache.
If the cache contains the partition of the variables needed by the command and all variables are in a single destination partition, the client can atomically multicast the command to the partition and avoid contacting the oracle. 

The client still needs to contact the oracle in one of these situations:
%(a)~according to client's cache, not all variables accessed by the command are in the same partition and it is necessary to move variables;
%(b)~the cache contains outdated information, and the command is multicast to a partition that does not contain all needed variables; or
(a)~the cache contains outdated information; or
(b)~the command is a create, in which it must involve the oracle, as explained before.
%If the cache contains outdated information and the addressed partition does not contain all the variables accessed by the command, the partition tells the client to retry the command.
If the cache contains outdated information and the addressed partition does not have the information of all the variables accessed by the command, the partition tells the client to retry the command.
In this case, the client contacts the oracle and then updates its cache with the oracle's response.

\textbf{Subgraph on servers}. If all partitions have to keep a copy of the the workload graph, scaling is also a problem if the graph grows over time. Thus, servers only keep a subgraph of variables they hold and the neighbors of those objects, by observing the access pattern of the commands. Using this subgraph only, the servers can compute the destination partition for commands without the need of the full graph.

\input{correctness}




