%!TEX root =  main.tex
\section{State partitioning with \dynastar}
%\section{Optimized dynamic state partitioning with \dynastar}
\label{sec:dynastar}

In this section, we overview \dynastar's key ideas, present the protocol in detail, discuss some performance optimizations, and argue about \dynastar's correctness.

\subsection{Overview}
%\subsection{State partitioning as a graph problem}

%\dynastar improves DS-SMR to cope with workloads that exhibit both strong and weak locality.
%In the presence of strong locality, \dynastar converges more quickly than the decentralized dynamic scheme.
%Under weak locality (i.e., workloads that cannot be perfectly partitioned), \dynastar largely outperforms DS-SMR.

The key insights of \dynastar are to create the workload graph on-the-fly and use graph partitioning techniques to efficiently relocate application state on-demand.
\begin{itemize}
\item \emph{On-the-fly workload modeling.}
\dynastar models a service workload as a graph $G = (V, E)$, where vertices represent state variables and edges dependencies between variables.
An edge connects two variables in the graph if a command accesses both of them.
A location oracle builds the workload graph based on feedback from the clients or partitions, as commands are executed.
\item \emph{On-demand relocation of service state.}
Periodically, the oracle computes a partitioning of the workload graph and multicasts to the partitions.
Based on this partitioning and the current location of variables, the partitions determine the destination for commands that access variables spread over multiple partitions.
Variables are moved on demand to the destination partition where the command will be executed. After the execution, variables are moved back to the source partition to keep the optimized partitioning.
\end{itemize}

In \dynastar a move request is multicast together with the command that triggered the request.
%a partition executes a command right after it has gathered all variables it needs.
Therefore, differently from DS-SMR, \dynastar ensures termination without resorting to expensive mechanisms (i.e., S-SMR).


\subsection{The \dynastar protocol}

Algorithms~\ref{alg:client_proxy}, \ref{alg:server_proxy}, and \ref{alg:oracle_proxy} describe the client, server and oracle processes, respectively. 
For brevity, we omit the delete command since the coordination involved in the create and delete commands are analogous. 
In the discussion in this section, every command involves the oracle.
The oracle is replicated and handled as a partition.
In the next section, we explain how clients can use a cache to avoid the oracle in the execution of most commands.


\subsubsection{The client process} 

To execute a command, the client atomically multicasts the command to the oracle (Algorithm 1).
The oracle replies with a prophecy, which may already tell the client that the command cannot be executed (e.g., it needs a variable that does not exist, it tries to create a variable that already exists).
If the command can be executed, the client receives a prophecy containing the partition where the command will be executed. The client then waits for the result of the execution of the command.


% The client must retry the command if the partition cannot execute the command.
% This happens if the cache on client is invalid, some of the variables needed by the command were moved to another partition due a new partitioning. 
%To ensure that a command is eventually executed, after retrying a few times, the client falls back to using \ssmr{}, multicasting the command to all partitions (and the oracle, in case of a create or delete command).

\subsubsection{The server process} 

All servers keep a workload graph in their memory. When a server delivers a command $C$, multicast by the oracle, it first checks if it has all variables needed by the command. If the server has all such variables, it executes the command and sends the response back to the client (Tasks 1a and 3 in Algorithm~\ref{alg:server_proxy}).
If not all the variables needed by the command are in that partition, the server issues a move command that involves all partitions containing the needed variables (Task 1b and 2).
%If one or more variables are not stored in a single partition, the server returns a message to the client to retry the operation.
%This happens if the oracle moved some variables to another partition as part of another command. 
In this case, a server in the source partitions reliably multicasts all the needed variables stored locally to the destination partition and waits to receive them back.
Destination partition waits for a message from each source partition. Once all variables needed are available, destination partition executes the command $C$, sends the response back to the client, and returns the variables to their source.
Periodically, the servers deliver a new partitioning plan from the oracle (Task 4). Each server will send the variables to the designated partition as in the plan and wait for variables from other partitions. Once a server receives all variables, it updates its location map accordingly.
%When a server delivers a message to create a variable (and similarly to delete an existing variable), it coordinates with the oracle (Task 3).
%The exchange of signals between the partition where the variable will be created and the oracle ensures that interleaved executions between create and delete commands will not lead to violations of linearizability (i.e., this is essentially the execution of a multi-partition command involving the oracle and a partition~\cite{bezerra2014ssmr}).
To determine the destination partition for a command, the servers uses the last computed partitioning.

\subsubsection{The oracle} 

When the oracle delivers a request, it distinguishes between two cases (Task 1 in Algorithm~\ref{alg:oracle_proxy}).
\begin{itemize}
\item If the command is to create a variable $v$, and $v$ does not already exist, the oracle chooses a random partition for $v$, multicasts the create command to the partition and itself, and returns the partition to the client as a prophecy (Figure~\ref{fig:oracle_repartition}).
\item If the command reads and writes existing variables, the oracle first checks that all such variables exist.
If the variables exist and they are all in a single partition, the oracle multicasts the command to that partition for execution.
If the variables are distributed in multiple partitions, the oracle determines the destination partition, and atomically multicasts a command to the involved partitions and to itself so that all variables are gathered at the destination partition.
The destination partition executes the command once it has received all variables needed by the command, then returns those variables to their source partition.

%In either case, oracle returns a prophecy back to the client with the destination partition.
\end{itemize}

\input{algorithm_client_proxy}
\input{algorithm_server_proxy}
\input{algorithm_oracle_proxy}

\begin{figure*}
\begin{minipage}[b]{1\linewidth} % A minipage that covers the whole width of the page
\centering
      \includegraphics[width=0.9\linewidth]{figures/dynastar}
\end{minipage}
\caption{The execution of a create command and a write command in \dynastar.}
\label{fig:oracle_repartition}
\end{figure*}

Upon delivering a create (Task 2), the oracle updates its partition information.
As part of a create command, the oracle coordinates with the partition to ensure correctness (Task 3)~\cite{bezerra2014ssmr}.
%
The oracle also keeps track of the workload graph by receiving hints with variables (i.e., vertices in the graph) and executing commands (i.e., edges in the graph). These hints can be submitted by the clients or by the partitions, which collect data upon executing commands and periodically inform the oracle (Task 4).
The oracle computes a partitioning plan of the graph and multicasts it to all servers and to itself. Upon delivering new partition plan, the oracle updates its location map accordingly (Task 5).
% The oracle also keeps track of the workload graph, computes a partitioning of the graph, and determines the destination partition for move operations.
% To maintain the workload graph (Task 5), the oracle receives hints with variables (i.e., vertices in the graph) and executed commands (i.e., edges in the graph).

To compute an optimized partitioning, the oracle uses a graph partitioner.
A new partitioning can be requested by the application, by a partition, or by the oracle itself (e.g., upon delivering a certain number of hints).
To determine the destination partition of a set of variables, as part of a move, the oracle uses 
% the current location of variables and 
the last computed partitioning.

\subsection{Performance optimizations}
%\subsection{Performance optimizations}
\label{sec:optm}

\textbf{Caching.} In the algorithm presented in the previous section, clients always need to involve the oracle, and the oracle dispatches every command to the partitions for execution.
Obviously, if every command involves the oracle, the system is unlikely to scale, as the oracle will likely become a bottleneck.
To address this issue, clients are equipped with a location cache.
Before submitting a command to the oracle, the client checks its location cache.
If the cache contains the partition of the variables needed by the command and all variables are in a single destination partition, the client can atomically multicast the command to the partition and avoid contacting the oracle. 

The client still needs to contact the oracle in one of these situations:
%(a)~according to client's cache, not all variables accessed by the command are in the same partition and it is necessary to move variables;
%(b)~the cache contains outdated information, and the command is multicast to a partition that does not contain all needed variables; or
(a)~the cache contains outdated information; or
(b)~the command is a create, in which it must involve the oracle, as explained before.
%If the cache contains outdated information and the addressed partition does not contain all the variables accessed by the command, the partition tells the client to retry the command.
If the cache contains outdated information and the addressed partition does not have the information of all the variables accessed by the command, the partition tells the client to retry the command.
In this case, the client contacts the oracle and then updates its cache with the oracle's response.

\textbf{Subgraph on servers}. If all partitions have to keep a copy of the the workload graph, scaling is also a problem as the graph is growing over time. Thus, servers only keep a subgraph of variables they are holding and the neighbors of those objects, by observing the access pattern of the commands. Using this subgraph only, the servers can compute the destination partition for executing commands without the need of having the full graph.

\input{correctness}




