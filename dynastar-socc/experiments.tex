%!TEX root =  main.tex
\section{Performance evaluation}
\label{sec:experiments}

In this section, we evaluate \dynastar{} according to various metrics,
under a variety of different operational parameters.  As a
representative application, we use the \appname{} social networking
service described in the previous section.  As a point of comparison,
we perform the same experiments with both
\ssmr{}~\cite{bezerra2014ssmr} and \dssmr. Our experiments show that
\dynastar{} is able to rapidly adapt to changing workloads, while
achieving throughputs and latencies far better than the existing
state-of-the-art approaches to partitioning.


\subsection{Experiemental environment}
\label{sec:evaluation:setup}

We conducted all experiments on a cluster with two types of nodes: (a)
HP SE1102 nodes, equipped with two Intel Xeon L5420 processors running
at 2.5 GHz and with 8 GB of main memory, and (b) Dell SC1435 nodes,
equipped with two AMD Opteron 2212 processors running at 2.0 GHz and
with 4 GB of main memory. The HP nodes were connected to an HP
ProCurve 2920-48G gigabit network switch, and the Dell nodes were
connected to another, identical switch. Those switches were
interconnected by a 20 Gbps link.  All nodes ran CentOS Linux 7.1 with
kernel 3.10 and had the OpenJDK Runtime Environment~8 with the
\mbox{64-Bit} Server VM (build 25.45-b02). In all experiments, the oracle 
had the same resources as every other partition: 2 replicas and 3 acceptors 
(in total five nodes per partition).


\subsection{Methodology and goals}
\label{sec:evaluation:methodology}

The experiments explore the following questions:
\begin{itemize}
\item \emph{How does \dynastar performance compare to other approaches?} 
\item \emph{How does the number of partitions affect the performance of posts for a fixed social graph?}
\item \emph{How does \dynastar perform under dynamic workloads?}
\item \emph{When will the oracle become a bottleneck?}
\end{itemize}



\paragraph*{Social network graph creation}
%
To generate the social graphs used in the experiments, we used the
Holme-Kim model~\cite{holme-kim}. We created power-law graphs (also
known as scale-free graphs) with a clustering coefficient varying from
0.6 to 1, which represent the geometric structures of social
networks. The coefficient is the probability that whenever an edge
$(v, w)$ is added to the graph, $v$ connects to some neighbour of $w$.
In the experiments, we tested graphs with 10000 users. We characterize
different workloads by varying the percentage of edge-cuts.  For
example, a graph with a 5\% edge cut means that 5\% of the total edges
in the graph have connected vertices located in different partitions.
Graphs with some percentage of edge-cuts have \emph{weak locality}.

\paragraph*{Command generation}
%
As a workload for the social graph, we have simulated clients,
and each client issues a sequence of post
commands.  For each command, the client selects a random node as
the poster.  We focused on post commands, since they may access
multiple partitions. Each client operate synchronously,
waiting for a response from the storage.

\begin{figure*}[ht!]
	\includegraphics{figures/socc/socc-throughput-latency-avg-all}
	\caption{Throughput and latency, varying edge-cuts for different partitioning size. 
  Throughput is shown in thousands of commands per second (kcps). 
  Latency is measured in milliseconds (bars show average and whiskers show 95-th percentile).}
	\label{fig:varying_edge_cut}
\end{figure*}



\paragraph*{Performance metrics}
%
The latency was measured as the end-to-end time between issuing the
command, and receiving the response.  Throughput was measured as the
number of posts/second that the clients were able to send.

\paragraph*{Operational parameters}
%
With post commands, the frequency of single-partition
vs. multi-partition commands depends on the number of partitions, the
geometry of the social graph, and the technique used to partition the
data. We ran experiments with 2, 4, and 8 partitions.  To vary the
geometry, we generated graphs with varying percentages of edge-cuts as
computed by METIS on a static graph. Our experiments used graphs with
0\%, 1\%, 5\% and 10\% of edge cuts. We configured METIS to keep the size of 
the most unbalanced partition up to 30\% more than the average partition size.
As already mentioned, we compared three strategies: \ssmr{}, \dssmr, and \dynastar.


\subsection{\dynastar vs. alternative systems}
\label{sec:evaluation:results}

Figure~\ref{fig:varying_edge_cut} shows the peak throughput and average latency of the three strategies, 
as we vary the number of partitions for social networks with different percentages of edge cuts.

All three techniques perform similarly on experiments with
strong locality, because there are no cross-partition commands after
the graph is perfectly partitioned. No more moves occur in
\dynastar or \dssmr, and no synchronization among partitions is
necessary for \ssmr in this case. 
Consequently, all three schemes scale remarkably well, and
the difference in throughput between each technique is due to the implementation of each one.
Although \dynastar and DS-SMR have comparable performance, they differ in an important way. 
As shown in Figure~\ref{fig:motivation} (top left graph) for 4 partitions, \dynastar converges 
to maximum throughput after 20 seconds from the beginning of the execution, while it takes 
DS-SMR (decentralized dynamic scheme) about 80 seconds to converge.

With social networks that exhibit weak locality (edge cut percentage greater than zero) \dssmr\ performance decreases significantly.  
This happens because with weak locality, objects in \dssmr\ are constantly being moved back and forth between partitions 
without converging to a stable configuration.%(see also Figure~\ref{fig:motivation}, graph on the bottom right, for 4 partitions). 
In contrast, for \dynastar and \ssmr with an optimized partitioning, we see that the throughput scales with the number of partitions up to 10\% of edge cuts. 
With 10\% of edge cuts and above, the overhead from moves (in \dynastar) and cross-partition commands (in S-SMR) outweighs the gains from additional partitions.

\begin{figure}[ht]
	\includegraphics[width=0.95\columnwidth]{figures/socc/socc-throughput-avg-vary-partition}
	\caption{Performance of social graph with increasing partitions.}
	\label{fig:4p1p_varying_partition_size}
\end{figure}

\begin{figure*}[h!]
  \centering
  \begin{subfigure}[b]{0.45\textwidth}
    \centering
    \includegraphics[width=0.95\columnwidth]{figures/socc/socc-dynamicload-tp}
    \caption{\dynastar versus DS-SMR}
  \end{subfigure}
  \begin{subfigure}[b]{0.45\textwidth}
    \centering
    \includegraphics[width=0.95\columnwidth]{figures/socc/socc-dynamicload-graph}
    \caption{The creation of a social network graph}
  \end{subfigure}
    \caption{Performance under dynamic workload.}
	\label{fig:dynamic_load_tput}
\end{figure*}

% We can draw similar results about the latency of the three strategies (Figure~\ref{fig:varying_edge_cut}, graphs on the bottom).
% The large number of move operations in DS-SMR with social graphs that cannot be perfectly partitioned result in increased latency.


\subsection{The ideal number of partitions}
\label{sec:evaluation:results}

While in the previous section we considered executions with a fixed percentage of edge cuts.
%, as we increased the number of partitions 
%(by adjusting the social graph clustering coefficient),
We now consider a fixed graph and vary the number of partitions.
Increasing the number of partitions with a fixed graph introduces a tradeoff.
On one hand, additional partitions improve performance as there are more resources to execute posts.
On the other hand, the number of edge cuts increases with the number of partitions, which hurts performance as there are additional moves.
We evaluate the performance of \dynastar and \ssmr with an optimized partitioning.% when subject to this tradeoff. 

Figure~\ref{fig:4p1p_varying_partition_size} shows that throughput scales with the number of partitions until partitioned in more than 6 partitions.
For each configuration, we computed the percentage of edge cuts and found that for 2, 3, 4, 6 and 8 partitions the percentages were respectively 
0.13\%, 0.88, 1.06\%, 2.28\% and 2.67\%.
Notice that only post operations are subject to this tradeoff since they may involve multiple partitions.
The most common operation in social networks is the request to read a user timeline. This is a single-partition
command in our application and as a consequence it scales linearly with the number of partitions.


\subsection{Performance under dynamic workloads}

Figure~\ref{fig:dynamic_load_tput} (left) depicts dynamically repartitioning
on-the-fly.  We started the system with an empty graph. Then clients
continuously create users and connections between them during the experiment
by executing the follow command.
The rate at which users and connections are created is shown in Figure~\ref{fig:dynamic_load_tput} (right).
The oracle monitors changes in the
graph's structure and was configured to trigger a repartitioning after receiving a number of hints
%(object creating and connecting)
from the partitions.
%after all users were in the system and after 300 seconds into the execution.
%when the number of changes exceed a threshold.  
%When the repartitioning took place, the partitioning became better and helped the throughput increase.
%We also show the behavior of DS-SMR.
When the repartitioning took place, the previously random user mapping got a better location from the oracle.
After the repartitioning, the clients triggered the users to move to a better partition. 
The partitioning became better and thus the throughput increased.
We also show the behavior of DS-SMR.
When few connections are in the system, most of the posts are single-partition commands, but as connections are added, moves are needed to execute posts and performance decreases quickly.

%\begin{figure}[ht]
%	\includegraphics{figures/experiments/dynamicload-tp-move-4p}
%	\caption{Adding nodes and repartitioning dynamically}
%	\label{fig:dynamic_load_tput}
%\end{figure}
%\begin{figure}[ht]
%	\includegraphics{figures/experiments/dynamicload-graph-structure}
%	\caption{Changes in dynamic workloads}
%	\label{fig:dynamic_load_changes}
%\end{figure}

\subsection{The performance of the oracle}

\dynastar differs from \dssmr\ in that it uses a centralized oracle
that maintains a global view of the workload graph. The oracle allows
\dynastar to make better choices about data movement, resulting in an overall
better throughput and lower latency. However, introducing a centralized
component in a distributed system is always a cause for some skepticism,
in case the component becomes a bottleneck, or a single point of failure. 
We therefore setup the oracle as a replicated partition 
and conducted two experiments to evaluate if the \dynastar oracle is a bottleneck to
system performance. The results show that the load on the oracle is
low, suggesting that \dynastar scales well.


The first experiment assesses the scalability of the METIS algorithm only.
We measured the time to compute the partitioning solution, and
the memory usage of the algorithms for increasingly large graphs. 
The results, depicted in Figure~\ref{fig:metis_size_time}, show that METIS scales
linearly in both memory and computation time on graphs of up to 10 million vertices.

\begin{figure}[ht!]
  \centering
    \includegraphics[width=\columnwidth]{figures/metis_size_time}
	\caption{METIS processor and memory usage.}
	\label{fig:metis_size_time}
\end{figure}

The second experiment evaluates the oracle in terms of CPU load over
time, for varying numbers of partitions. The results are shown in
Figure~\ref{fig:cpu_oracle}. The load is higher in the
beginning of the experiment, when the clients had not yet cached the
requests and the oracle was busy moving the state. However, the load diminishes rapidly, and remains relatively
low over time. This is because access to the oracle is necessary only
when clients have an invalid cache or when a repartition happens. This experiments
suggest that the oracle would not become a bottleneck.% for reasonably large
%deployments.

\begin{figure}[ht]
	\includegraphics[width=\columnwidth]{figures/socc/socc-oracle-load}
	\caption{CPU load in the oracle.}
	\label{fig:cpu_oracle}
\end{figure}

