%!TEX root =  main.tex
\section{Implementation}
\label{sec:implementation}

\subsection{Atomic multicast}

Our \dynastar prototype uses the BaseCast atomic multicast protocol described in \cite{Coelho:2017} and available as open source.\footnote{https://bitbucket.org/paulo\_coelho/libmcast}
Each group of servers in BaseCast executes an instance of Multi-Paxos.\footnote{http://libpaxos.sourceforge.net/paxos\_projects.php\#libpaxos3}
Groups coordinate to ensure that commands multicast to multiple groups are consistently ordered (as defined by the atomic multicast properties \S\ref{sec:amcast}).
%Commands multicast to multiple groups coordinate to ensure that commands are consistently ordered (as defined by the atomic multicast properties \S\ref{sec:amcast}).
BaseCast is a genuine atomic multicast in that only the sender and destination replicas of a multicast message communicate to order the multicast message. 
%A genuine atomic multicast is the foundation of scalable systems, since it does not rely on a fixed group of processes and does not involve all processes.

\subsection{\dynastar}

Our  \dynastar prototype is written as a
Java 8 library.
%All code, including the experiment harness,
% The code is publicly available as open-source.
%\footnote{https://www.gnu.org/licenses/old-licenses/lgpl-2.1.en.html}
Application designers who use \dynastar
 to implement a replicated service must extend three key classes:
 \begin{itemize}
 \item[--] \emph{PRObject}: provides a common interface for replicated data items.
 \item[--] \emph{PartitionStateMachine}: encapsulates the logic of the server
   proxy. Note that the server logic is written without knowledge of the actual partitioning scheme. The \dynastar library
   handles all communication between partitions and the oracle transparently.
 \item[--] \emph{OracleStateMachine}: computes the mapping of objects to partitions.
Our default implementation uses METIS\footnote{http://glaros.dtc.umn.edu/gkhome/views/metis} to provide a partitioning based on the workload graph.
While partitioning a graph, METIS aims to reduce the number of multi-partition commands (edge-cuts) while trying to keep the various partitions balanced. 
We configured METIS to allow a 20\% unbalance among partitions. 
 \end{itemize}

 We note one important implementation detail.  The oracle is
 multi-threaded, and can service requests while computing a new
 partitioning concurrently. To ensure that all replicas start using
 the new partitioning consistently, the oracle identifies each
 partitioning with a unique id.  When an oracle replica finishes a
 repartitioning, it atomically multicasts the id of the new
 partitioning to all replicas of the oracle.  The first delivered id
 message defines the order of the new partitioning with respect to
 other oracle operations.

%% In this section, we describe \libname{}, a library that implements
%% both \ssmr{}, \dssmr{} and \dynastar{}.  We also present \appname{}, a
%% scalable social network application built with
%% \libname{}. \libname\ and \appname\ were both implemented in Java.

%% \subsection{\libname}

%% \libname{} implements functionalities of static and dynamic mapping,
%% and supports centralized and decentralized partitioning schemes.
%% There are three classes that the developer (i.e., application
%% designer) must extend to implement a replicated service with
%% \libname{}: PRObject, PartitionStateMachine, OracleStateMachine.

%% The \emph{PRObject class} represents any kind of data item that is
%% part of the service state. The state is partially replicated (i.e.,
%% objects are distributed among partitions). Therefore, when executing a
%% command, a replica might not have local access to some of the objects
%% involved in the execution of the command. The developer informs
%% \libname{} which object classes are partially replicated by extending
%% the PRObject class. Each object of such a class is stored locally or
%% remotely, but the application code is agnostic to the location of an
%% object. All calls to methods of such objects are intercepted by
%% \libname{}, transparently to the developer.

%% The \emph{PartitionStateMachine class} represents logic of the server
%% proxy. The application server class must extend the
%% PartitionStateMachine class. To execute commands, the developer must
%% provide an implementation for the method executeCommand(Command). The
%% code for such a method is agnostic to the existence of partitions. In
%% other words, developer programs for classical state machine
%% replication (i.e., full replication). \libname{} is responsible for
%% handling all communication between partitions and oracle
%% transparently. Objects that are involved in application's command will
%% be available to the partition at the time it is accessed by the
%% partitions. To start the server, method runStateMachine() is
%% called. Method createObject() also needs to be implemented, where the
%% developer defines how new state objects are loaded or created.


%% The \emph{OracleStateMachine class} defines the oracle, which is
%% deployed as a partition.  Because the oracle is in charge of moving
%% the PRObjects to the appropriate partitions, it requires a partitioner
%% that will provide for each object a desired location. A default
%% partitioner is implemented using METIS, a state-of-the-art graph
%% partitioner, but any algorithm that takes as input a graph and outputs
%% a mapping of objects to partitions is a valid partitioner.  The
%% workload graph is built by aggregating hints about the objects' access
%% patterns, and the mapping it returns indicates the ideal partition for
%% each object. Since the partitioner is executed in every oracle
%% replica, its output should be deterministic so all the replicas
%% transition to the same state after the partitioning.  The developer
%% can override the default algorithm to partition the graph and the
%% oracle is agnostic to its internal behavior.  At any time, the
%% application can request a repartitioning of the graph.

\subsection{TPC-C benchmark}
\label{sec:imp:tpcc}

%On average, 10\% of transactions are distributed transactions. 

The TPC-C benchmark is an industry standard for evaluating the performance of OLTP systems.
It has 9 tables and five transaction types that simulate a warehouse-centric 
order processing application: \emph{New-Order} (45\% of transactions in the workload), \emph{Payment} (43\%), \emph{Delivery}
(4\%), \emph{Order-Status} (4\%) and \emph{Stock-Level} (4\%).
%The ITEM table is replicated to all servers, considering that the ITEM table is not updated in this benchmark.
We implemented a Java version of the TPC-C benchmark that runs on top of \dynastar. 
Each row in TPC-C tables is an object in \dynastar. The oracle models the workload at the granularity of districts,
thus each district or warehouse is a node in the graph. If a transaction accesses a district 
and a warehouse, the oracle will create an edge between that district and the warehouse.
The objects (e.g., customers, orders) that belong to a district 
are considered part of district. However, if a transaction requires
objects from multiple district, only those objects will be moved on demand, rather than
the whole district.
%A transaction is a set of commands that access those variables, implemented 
%as server procedures. 

\subsection{\appname\ social network service}
\label{sec:imp:\appname}

For the purposes of micro benchmark, we have developed a Twitter-like
social network service using the \dynastar{} library.  In our social
network, users can follow, unfollow, post, or read other users' tweets
according to whom the user is following. Like Twitter, users are
constrained to posting 140-character messages.

Each user in the social network corresponds to a node in a graph. If
one user follows another, then a directed edge is created from the
follower to the followee. Each user has an associated \emph{timeline},
which is a sequence of post messages from the people that the user
follows. Thus, when a user issues a post command, it results in
writing the message to the timeline of all the user's followers.  In
contrast, when users read their own timeline, they only need
to access the state associated with their own node.

Since DynaStare guarantees linearizable executions, any causal dependencies between posts in \appname\ will be seen in the correct order. 
More precisely, if user B posts a message after receiving a message posted by user A, no user who follows A and B will see B's message before seeing A's message.

Overall, in \appname, post, follow or unfollow commands can lead to
object moves.  Follow and unfollow commands can involve at most two
partitions, while posts may require object moves from many partitions.

%Of course, other implementations are possible. But, given that users
%in social networks spend most of the time reading (i.e., performing
%getTimeline)~\cite{facebookTAO}, it is useful to implement getTimeline
%as an efficient single-partition command.


\subsection{Alternative system}

Throughout our evaluation, we compare \dynastar{} to an optimized version of S-SMR~\cite{bezerra2014ssmr} and DS-SMR~\cite{hoang2016}, available in public repositories.\footnote{https://bitbucket.org/kdubezerra/eyrie,https://bitbucket.org/usi-dslab/ds-smr}
S-SMR has been shown to scale performance with the number of partitions under a variety of workloads.
It differs from \dynastar{} in two important aspects:
multi-partition commands are executed by all involved partitions, after the partitions exchange needed state for the execution of the command and S-SMR supports static state partitioning.
In our experiments, we manually optimize S-SMR's partitioning with knowledge about the workload.
In the experiments, we refer to this system and configuration as S-SMR*.
%Since
%all three systems (S-SMR, DS-SMR, and \dynastar) provide a common
%application-level interface, there was no additional work required to
%port the social network application.

