
Sharding and replication are the mechanisms of choice of most scalable and fault-tolerant distributed systems.
The performance of a sharded system, however, heavily depends on the partitioning of the data: in order to scale, most commands must involve a single shard and load must be balanced across shards.
Estimating a good partitioning of the application state is challenging since it requires a priori information about the workload.
Moreover, even if such information is available, access patterns may change during system execution.
A good partitioning of the data for uniform access patterns may lead to poor performance under skewed access patterns.
The paper introduces DynaStar, a scalable and fault-tolerant system that supports dynamic state partitioning.
This means that DynaStar does not require a priori knowledge about the workload and can seamlessly adapt to workload variations.
The paper describes DynaStar design and implementation, and presents a detailed performance evaluation using two benchmarks, a social network based on real data and TPC-C.

